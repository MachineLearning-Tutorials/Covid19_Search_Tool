{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cepc_sQETKhK"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zqI2rescS2Ne",
    "outputId": "c483fe0d-b87e-4917-aae0-f7756939a357"
   },
   "outputs": [],
   "source": [
    "# scientific and numberical libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#general libraries\n",
    "from pathlib import Path, PurePath\n",
    "import requests\n",
    "from requests.exceptions import HTTPError, ConnectionError\n",
    "import re, os, sys\n",
    "import logging\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "\n",
    "# Import Tensorflow libraries \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.estimator import Estimator\n",
    "from tensorflow.python.estimator.run_config import RunConfig\n",
    "from tensorflow.python.estimator.model_fn import EstimatorSpec\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "from bert_serving.server.graph import optimize_graph\n",
    "from bert_serving.server.helper import get_args_parser\n",
    "from bert_serving.server.bert.tokenization import FullTokenizer\n",
    "from bert_serving.server.bert.extract_features import convert_lst_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Covid19_Search_Tool/src to python path\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "data_dir = os.path.join(nb_dir,'src')\n",
    "if data_dir not in sys.path:\n",
    "    sys.path.append(data_dir)\n",
    "\n",
    "# Import local libraries\n",
    "from utils import ResearchPapers\n",
    "from nlp import SearchResults, WordTokenIndex, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from local folder\n",
    "Requires visiting [COVID-19 Open Research Dataset Challenge (CORD-19)](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge), downloading the data (you need a Kaggle account), then moving and unzipping the data in Covid19_Search_Tool/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download metadata from the CORD-19 dataset\n",
    "data_path = os.path.join(os.getcwd(), \"../data\",\"CORD-19-research-challenge\")\n",
    "metadata_path = os.path.join(data_path, 'metadata.csv')\n",
    "metadata = pd.read_csv(metadata_path,\n",
    "                               dtype={'Microsoft Academic Paper ID': str,\n",
    "                                      'pubmed_id': str})\n",
    "\n",
    "# Set the abstract to the paper title if it is null\n",
    "metadata.abstract = metadata.abstract.fillna(metadata.title)\n",
    "print(\"Number of articles BEFORE removing duplicates: %s \" % len(metadata))\n",
    "\n",
    "# Some papers are duplicated since they were collected from separate sources. Thanks Joerg Rings\n",
    "duplicate_paper = ~(metadata.title.isnull() | metadata.abstract.isnull() | metadata.publish_time.isnull()) & (metadata.duplicated(subset=['title', 'abstract']))\n",
    "metadata.dropna(subset=['publish_time', 'journal'])\n",
    "metadata = metadata[~duplicate_paper].reset_index(drop=True)\n",
    "print(\"Number of articles AFTER removing duplicates: %s \" % len(metadata))\n",
    "\n",
    "# Create data classes for the dataset and paper\n",
    "papers = ResearchPapers(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67PH21y__XYn"
   },
   "source": [
    "# Create a BERT sentance encoding search engine \n",
    "From: https://towardsdatascience.com/building-a-search-engine-with-bert-and-tensorflow-c6fdc0186c8a\n",
    "By: Denis Antyukhov\n",
    "In this experiment, we will use a pre-trained BERT model checkpoint to build a general-purpose text feature extractor.\n",
    "\n",
    "These things are sometimes referred to as Natural Language Understanding (NLU) modules, because the features they extract are relevant for a wide array of downstream NLP tasks.\n",
    "\n",
    "One use for these features is in instance-based learning, which relies on computing the similarity of the query to the training samples.\n",
    "\n",
    "We will illustrate this by building a simple Information Retrieval system using the BERT NLU module for feature extraction.\n",
    "\n",
    "**The plan for this experiment is:**\n",
    "1. getting the pre-trained BERT model checkpoint\n",
    "2. extracting a sub-graph optimized for inference\n",
    "3. creating a feature extractor with tf.Estimator\n",
    "4. exploring vector space with T-SNE and Embedding Projector\n",
    "5. implementing an Information Retrieval engine\n",
    "6. accelerating search queries with math\n",
    "7. building a covid research article recommendation system\n",
    "\n",
    "### Step 1: getting the pre-trained model\n",
    "We start with a pre-trained english BERT-base model checkpoint.\n",
    "\n",
    "For configuring and optimizing the graph for inference we will use bert-as-a-service repository, which allows for serving BERT models for remote clients over TCP.\n",
    "\n",
    "Having a remote BERT-server is beneficial in multi-host environments. However, in this part of the experiment we will focus on creating a local (in-process) feature extractor. This is useful if one wishes to avoid additional latency and potential failure modes introduced by a client-server architecture. Now, let us download the model and install the package.\n",
    "\n",
    "_This task was completed via install commands in the README!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aGlziSVYK0gy"
   },
   "source": [
    "## Step 2: optimizing the inference graph\n",
    "Normally, to modify the model graph we would have to do some low-level TensorFlow programming. \n",
    "\n",
    "However, thanks to bert-as-a-service, we can configure the inference graph using a simple CLI interface.\n",
    "\n",
    "There are a couple of parameters in the below snippet too look out for.\n",
    "\n",
    "For each text sample, BERT-base model encoding layers output a tensor of shape **[sequence_len, encoder_dim],** with one vector per input token. To obtain a fixed representation, we need to apply some sort of pooling.\n",
    "\n",
    "**POOL_STRAT** parameter defines the pooling strategy applied to the  **POOL_LAYER** encoding layer. The default value **REDUCE_MEAN** averages the vectors for all tokens in a sequence. This strategy works best for most sentence-level tasks, when the model is not fine-tuned. Another option is NONE, in which case no pooling is applied at all. This is useful for word-level tasks such as Named Entity Recognition or POS tagging. For a detailed discussion of other options check out the Han Xiao's [blog post.](https://hanxiao.github.io/2019/01/02/Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ/)\n",
    "\n",
    "**SEQ_LEN** affects the maximum length of sequences processed by the model. Smaller values increase the model inference speed almost linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "vkYOjgI1_ep3",
    "outputId": "d40d750e-8dd9-403c-c3d4-3368f7358a85"
   },
   "outputs": [],
   "source": [
    "# base model dir\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "base_dir = os.path.join(nb_dir,'models')\n",
    "\n",
    "# input dir\n",
    "MODEL_DIR = os.path.join(base_dir,'uncased_L-12_H-768_A-12') #@param {type:\"string\"}\n",
    "VOCAB_PATH = os.path.join(MODEL_DIR, \"vocab.txt\") #@param {type:\"string\"}\n",
    "# output dir\n",
    "GRAPH_DIR = os.path.join(base_dir,'graph') #@param {type:\"string\"}\n",
    "# output filename\n",
    "GRAPH_PATH = os.path.join(GRAPH_DIR,'extractor.pbtxt') #@param {type:\"string\"}\n",
    "\n",
    "POOL_STRAT = 'REDUCE_MEAN' #@param ['REDUCE_MEAN', 'REDUCE_MAX', \"NONE\"]\n",
    "POOL_LAYER = '-2' #@param {type:\"string\"}\n",
    "SEQ_LEN = '256' #@param {type:\"string\"}\n",
    "\n",
    "print (\"MODEL_DIR:  %s\\nVOCAB_PATH: %s\\nGRAPH_PATH: %s\\nGRAPH_OUT:  %s\\n\"\n",
    "       %(MODEL_DIR, VOCAB_PATH, GRAPH_PATH, GRAPH_OUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive tf session\n",
    "sesh = tf.InteractiveSession()\n",
    "\n",
    "tf.gfile.MkDir(GRAPH_DIR)\n",
    "\n",
    "parser = get_args_parser()\n",
    "carg = parser.parse_args(args=['-model_dir', MODEL_DIR,\n",
    "                               '-graph_tmp_dir', GRAPH_DIR,\n",
    "                               '-max_seq_len', str(SEQ_LEN),\n",
    "                               '-pooling_layer', str(POOL_LAYER),\n",
    "                               '-pooling_strategy', POOL_STRAT])\n",
    "\n",
    "tmp_name, config = optimize_graph(carg)\n",
    "graph_fout = os.path.join(GRAPH_DIR, GRAPH_OUT)\n",
    "\n",
    "tf.gfile.Rename(\n",
    "    tmp_name,\n",
    "    graph_fout,\n",
    "    overwrite=True\n",
    ")\n",
    "print(\"\\nSerialized graph to {}\".format(graph_fout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9q2yDu4wLAkN"
   },
   "source": [
    "Running the above snippet will put the BERT model graph and weights from  **MODEL_DIR** into a GraphDef object which will be serialized to a pbtxt file at **GRAPH_OUT**. The file will be smaller than the original model because the nodes and variables required for training will be removed. This results in a quite portable solution: for example the english base model only takes 389 MB after exporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eARzl4sCLI7d"
   },
   "source": [
    "### Step 3: creating a feature extractor\n",
    "Now, we will use the serialized graph to build a feature extractor using the tf.Estimator API. We will need to define two things: **input_fn** and **model_fn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFrwq2AZLCkD"
   },
   "outputs": [],
   "source": [
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.INFO)\n",
    "log.handlers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z885uqROLSN6"
   },
   "source": [
    "**input_fn** manages getting the data into the model. That includes executing the whole text preprocessing pipeline and preparing a feed_dict for BERT. \n",
    "\n",
    "First, each text sample is converted into a tf.Example instance containing the necessary features listed in **INPUT_NAMES**. The bert_tokenizer object contains  the WordPiece vocabulary and performs the text preprocessing. After that the examples are re-grouped by feature name in a **feed_dict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-SMkDVYLP1N"
   },
   "outputs": [],
   "source": [
    "INPUT_NAMES = ['input_ids', 'input_mask', 'input_type_ids']\n",
    "bert_tokenizer = FullTokenizer(VOCAB_PATH)\n",
    "\n",
    "def build_feed_dict(texts):\n",
    "    \n",
    "    text_features = list(convert_lst_to_features(\n",
    "        texts, SEQ_LEN, SEQ_LEN, \n",
    "        bert_tokenizer, log, False, False))\n",
    "\n",
    "    target_shape = (len(texts), -1)\n",
    "\n",
    "    feed_dict = {}\n",
    "    for iname in INPUT_NAMES:\n",
    "        features_i = np.array([getattr(f, iname) for f in text_features])\n",
    "        features_i = features_i.reshape(target_shape).astype(\"int32\")\n",
    "        feed_dict[iname] = features_i\n",
    "\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpSMbxKKLYVe"
   },
   "source": [
    "tf.Estimators have a fun feature which makes them re-build and re-initialize the whole computational graph at each call to the predict function. \n",
    "\n",
    "So, in order to avoid the overhead, to the predict function we will pass a generator, which will yield the features to the model in a never-ending loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gne1y7etLaEj"
   },
   "outputs": [],
   "source": [
    "def build_input_fn(container):\n",
    "    \n",
    "    def gen():\n",
    "        while True:\n",
    "          try:\n",
    "            yield build_feed_dict(container.get())\n",
    "          except:\n",
    "            yield build_feed_dict(container.get())\n",
    "\n",
    "    def input_fn():\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types={iname: tf.int32 for iname in INPUT_NAMES},\n",
    "            output_shapes={iname: (None, None) for iname in INPUT_NAMES})\n",
    "    return input_fn\n",
    "\n",
    "class DataContainer:\n",
    "  def __init__(self):\n",
    "    self._texts = None\n",
    "  \n",
    "  def set(self, texts):\n",
    "    if type(texts) is str:\n",
    "      texts = [texts]\n",
    "    self._texts = texts\n",
    "    \n",
    "  def get(self):\n",
    "    return self._texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG8MrQ4ILc-l"
   },
   "source": [
    "**model_fn** contains the specification of the model. In our case, it is loaded from the pbtxt file we saved in the previous step. \n",
    "\n",
    "The features are mapped explicitly to the corresponding input nodes with input_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q8m5Uch7Lf9A",
    "outputId": "0e96da74-5ddd-4c61-86d4-fde71e21e529"
   },
   "outputs": [],
   "source": [
    "def model_fn(features, mode):\n",
    "    with tf.gfile.GFile(GRAPH_PATH, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    output = tf.import_graph_def(graph_def,\n",
    "                                 input_map={k + ':0': features[k] for k in INPUT_NAMES},\n",
    "                                 return_elements=['final_encodes:0'])\n",
    "\n",
    "    return EstimatorSpec(mode=mode, predictions={'output': output[0]})\n",
    "  \n",
    "estimator = Estimator(model_fn=model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTEqJGX5LpXH"
   },
   "source": [
    "Now we have everything we need to perform inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYv18IqcLnQ5"
   },
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def build_vectorizer(_estimator, _input_fn_builder, batch_size=128):\n",
    "  container = DataContainer()\n",
    "  predict_fn = _estimator.predict(_input_fn_builder(container), yield_single_examples=False)\n",
    "  \n",
    "  def vectorize(text, verbose=False):\n",
    "    x = []\n",
    "    bar = Progbar(len(text))\n",
    "    for text_batch in batch(text, batch_size):\n",
    "      container.set(text_batch)\n",
    "      x.append(next(predict_fn)['output'])\n",
    "      if verbose:\n",
    "        bar.add(len(text_batch))\n",
    "      \n",
    "    r = np.vstack(x)\n",
    "    return r\n",
    "  \n",
    "  return vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw33e3SRLnKm"
   },
   "outputs": [],
   "source": [
    "bert_vectorizer = build_vectorizer(estimator, build_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "iAAXDUrsLnGW",
    "outputId": "49bfec0a-6e6f-4b98-d6c1-3a34bfa29e3d"
   },
   "outputs": [],
   "source": [
    "bert_vectorizer(64*['sample']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_YuBehNMKvT"
   },
   "source": [
    "### Step 4: exploring vector space with Projector\n",
    "\n",
    "*A* standalone version of BERT feature extractor is available in the [repository](https://github.com/gaphex/bert_experimental).\n",
    "\n",
    "Using the vectorizer we will generate embeddings for articles from the CORD-19 benchmark (in this tutorial, the Reuters-21578 benchmark corpus was used previously)\n",
    "\n",
    "To visualise and explore the embedding vector space in 3D we will use a dimensionality reduction technique called [T-SNE](https://distill.pub/2016/misread-tsne/).\n",
    "\n",
    "Lets get the article embeddings first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "LrWW7qxLLm9Z",
    "outputId": "d69683d3-1e45-4c37-c25d-6212b98b5bf1"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7jibjLu9Tx6i",
    "outputId": "a92f1fe3-b74b-4510-ca5f-0bbd0d14d0d1"
   },
   "outputs": [],
   "source": [
    "type(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "3pSFM8TOM1wU",
    "outputId": "2d03fb15-6828-4670-8e7e-b067b1c6621c"
   },
   "outputs": [],
   "source": [
    "# REUTERS EXAMPLE\n",
    "max_samples = 256\n",
    "categories = ['wheat', 'tea', 'strategic-metal', \n",
    "              'housing', 'money-supply', 'fuel']\n",
    "\n",
    "S, X, Y = [], [], []\n",
    "\n",
    "for category in categories:\n",
    "  print(category)\n",
    "  \n",
    "  sents = reuters.sents(categories=category)\n",
    "  sents = [' '.join(sent) for sent in sents][:max_samples]\n",
    "  X.append(bert_vectorizer(sents, verbose=True))\n",
    "  Y += [category] * len(sents)\n",
    "  S += sents\n",
    "  \n",
    "X = np.vstack(X) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSAPjrWkNPZX"
   },
   "outputs": [],
   "source": [
    "with open(\"embeddings.tsv\", \"w\") as fo:\n",
    "  for x in X.astype('float16'):\n",
    "    line = \"\\t\".join([str(v) for v in x])\n",
    "    fo.write(line + \"\\n\")\n",
    "\n",
    "with open(\"metadata.tsv\", \"w\") as fo:\n",
    "  fo.write(\"Label\\tSentence\\n\")\n",
    "  for y, s in zip(Y, S):\n",
    "    fo.write(\"{}\\t{}\\n\".format(y, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqVYk769NiiB"
   },
   "source": [
    "The interactive visualization of generated embeddings is available on the [Embedding Projector](https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/gaphex/7262af1e151957b1e7c638f4922dfe57/raw/3b946229fc58cbefbca2a642502cf51d4f8e81c5/reuters_proj_config.json). **<--CLICK THAT TO GENERATE**\n",
    "\n",
    "From the link you can run T-SNE yourself, or load a checkpoint using the bookmark in lower-right corner (loading works only on Chrome).\n",
    "\n",
    "To reproduce the input files used for this visualization, run the code below. Then, download the files to your machine and upload to Projector\n",
    "\n",
    "(you can dowload files from the menu opened by the \">\" button in the upper-left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "colab_type": "code",
    "id": "bvqeITuSNjPk",
    "outputId": "58bc4de4-b815-419c-a297-a5c08dca6c31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSYC8R9zUH3E"
   },
   "source": [
    "### Create embeddings for CORD19 Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNknqrSIUL5g"
   },
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to nltk.corpus.reader.plaintext.CategorizedPlaintextCorpusReader\n",
    "# From: https://stackoverflow.com/questions/49088978/how-to-create-corpus-from-pandas-data-frame-to-operate-with-nltk/49104725\n",
    "def CreateCorpusFromDataFrame(corpusfolder,df):\n",
    "    for index, r in df.iterrows():\n",
    "        id=index\n",
    "        title=r['title']\n",
    "        body=r['title']\n",
    "        # handler text for not properly munged data\n",
    "        try: \n",
    "          category=re.sub('/', '', r['journal']) # remove odd characters as writing to file\n",
    "        except TypeError:\n",
    "          continue\n",
    "        fname=str(category)+'_'+str(id)+'.txt'\n",
    "        corpusfile=open(corpusfolder+'/'+fname,'a+')\n",
    "        corpusfile.write(str(body) +\" \" +str(title))\n",
    "        corpusfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XmAcjhVqV2kK",
    "outputId": "391a340e-2cd1-4d16-e99a-d501fdf86c7a"
   },
   "outputs": [],
   "source": [
    "# create folder to hold CORD19 nltk\n",
    "dirName = 'CORD19_nltk_title_only'\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# create corpus\n",
    "CreateCorpusFromDataFrame(dirName,metadata)\n",
    "print(\"Corpus created in folder: %s\" % dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yds9N-ggY4M2"
   },
   "outputs": [],
   "source": [
    "# Import the corpus reader\n",
    "from nltk.corpus.reader import CategorizedPlaintextCorpusReader\n",
    "\n",
    "# Create NLTK data structure (with pattern matching to create the article names again)\n",
    "CORD_corpus=CategorizedPlaintextCorpusReader(dirName,r'.*', cat_pattern=r'(.*)_.*.txt$') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "2kGn261zN8fZ",
    "outputId": "dcfcb04d-9975-4ee2-a24a-e8f868bf95b4"
   },
   "outputs": [],
   "source": [
    "# total journals\n",
    "print(\"Total number journals: %s\" % (len(metadata.journal.unique())))\n",
    "\n",
    "# select a subset of journals, where the journal will be the tag\n",
    "num_journals=8\n",
    "categories=metadata['journal'].value_counts()[:num_journals].index.tolist()\n",
    "print (\"\\nPicking most common journals:\")\n",
    "categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "v0jyk0_9LmmO",
    "outputId": "23ef4e54-f587-43c1-bc04-472c727d90ef"
   },
   "outputs": [],
   "source": [
    "#CORD19 Examples\n",
    "max_samples = 5000\n",
    "\n",
    "S, X, Y = [], [], []\n",
    "\n",
    "for category in categories:\n",
    "  print(category)\n",
    "  \n",
    "  sents = CORD_corpus.sents(categories=category)\n",
    "  sents = [' '.join(sent) for sent in sents][:max_samples]\n",
    "  X.append(bert_vectorizer(sents, verbose=True))\n",
    "  Y += [category] * len(sents)\n",
    "  S += sents\n",
    "  \n",
    "X = np.vstack(X) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0M5K6rEnt-X"
   },
   "outputs": [],
   "source": [
    "# make folder in google drive to download files\n",
    "location = '/content/drive/My Drive/'\n",
    "\n",
    "with open(location + \"embeddings_large.tsv\", \"w\") as fo:\n",
    "  for x in X.astype('float16'):\n",
    "    line = \"\\t\".join([str(v) for v in x])\n",
    "    fo.write(line + \"\\n\")\n",
    "\n",
    "with open(location + \"metadata_large.tsv\", \"w\") as fo:\n",
    "  fo.write(\"Label\\tSentence\\n\")\n",
    "  for y, s in zip(Y, S):\n",
    "    fo.write(\"{}\\t{}\\n\".format(y, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3JbwudUnzrU"
   },
   "source": [
    "The interactive visualization of generated embeddings is available on the [Embedding Projector](https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/gaphex/7262af1e151957b1e7c638f4922dfe57/raw/3b946229fc58cbefbca2a642502cf51d4f8e81c5/reuters_proj_config.json). **<--CLICK THAT TO GENERATE**\n",
    "\n",
    "Then go to bottom right and load in those files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jLduttHn2P1"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"900\" height=\"632\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/bert_resourses/reuters_tsne_hd.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CORD19 - NLP Challenge",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c23c2c03104af2bd42a5dfc02d8686": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "SearchTerms",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_77a56e3eb5f045d393e7a468d717c994",
      "placeholder": "​",
      "style": "IPY_MODEL_7286b8badb294af9a397db67ecad89c8",
      "value": "ACE spike"
     }
    },
    "5a4ffac021a54cbd9ed5928d417a86ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69f781068f1e4fcfb8cc5a71f8486e63": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0ff7ba534e6942c7a5625874cc2666a1",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "What is known about transmission, incubation, and environmental stability?\n"
       },
       {
        "metadata": {
         "tags": []
        },
        "output_type": "display_data",
        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>doi</th>\n      <th>authors</th>\n      <th>journal</th>\n      <th>publish_time</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Revisión sobre las infecciones no bacterianas ...</td>\n      <td>Resumen Aunque las bacterias son los principal...</td>\n      <td>10.1016/j.arbres.2015.02.015</td>\n      <td>Galván, José María; Rajas, Olga; Aspa, Javier</td>\n      <td>Archivos de Bronconeumología</td>\n      <td>2015-11-30</td>\n      <td>256.904116</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 12th Edition of the Scientific Days of the...</td>\n      <td>A1 The outcome of patients with recurrent vers...</td>\n      <td>10.1186/s12879-016-1877-4</td>\n      <td>Niculae, Cristian-Mihail; Manea, Eliza; Jipa, ...</td>\n      <td>BMC Infect Dis</td>\n      <td>2016 Nov 1</td>\n      <td>256.888407</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Influence of different glycoproteins and of th...</td>\n      <td>Host plasma membrane protein SERINC5 is incorp...</td>\n      <td>10.1101/780577</td>\n      <td>Diehl, W. E.; Guney, M. H.; Kyawe, P. P.; Whit...</td>\n      <td>NaN</td>\n      <td>2019-09-24</td>\n      <td>256.872104</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Coronavirus immunogens</td>\n      <td>Abstract Coronaviruses (CV) infect a variety o...</td>\n      <td>10.1016/0378-1135(93)90030-B</td>\n      <td>Saif, Linda J.</td>\n      <td>Veterinary Microbiology</td>\n      <td>1993-11-30</td>\n      <td>256.812236</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sources et devenir des micro-organismes pathog...</td>\n      <td>Résumé Un grand nombre d’infections humaines d...</td>\n      <td>10.1016/S1773-035X(14)72362-7</td>\n      <td>Baudart, Julia; Paniel, Nathalie</td>\n      <td>Revue Francophone des Laboratoires</td>\n      <td>2014-02-28</td>\n      <td>256.795673</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Apport de la biologie moléculaire dans l’ident...</td>\n      <td>Résumé Les débuts de la virologie furent longs...</td>\n      <td>10.1016/S1773-035X(09)70307-7</td>\n      <td>Borde, Chloé; Maréchal, Vincent; Barnay-Verdie...</td>\n      <td>Revue Francophone des Laboratoires</td>\n      <td>2009-12-31</td>\n      <td>256.198831</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Progress towards a higher taxonomy of viruses</td>\n      <td>Summary The current consensus view is that a h...</td>\n      <td>10.1016/S0923-2516(06)80059-2</td>\n      <td>Ward, C.W.</td>\n      <td>Research in Virology</td>\n      <td>1993-12-31</td>\n      <td>256.198763</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Identification and Characterization of a Ribos...</td>\n      <td>The order Nidovirales currently comprises four...</td>\n      <td>10.1128/JVI.00658-16</td>\n      <td>Zeng, Cong; Wu, Andong; Wang, Yi; Xu, Shan; Ta...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>256.198509</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>In vitro antimicrobial activities of animal-us...</td>\n      <td>BACKGROUND: The quinoxaline 1,4-di-N-oxides (Q...</td>\n      <td>10.1186/s12917-016-0812-7</td>\n      <td>Zhao, Yan; Cheng, Guyue; Hao, Haihong; Pan, Yu...</td>\n      <td>BMC Vet Res</td>\n      <td>2016 Sep 6</td>\n      <td>256.198353</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Indoor air pollution and exposure assessment o...</td>\n      <td>Abstract Indoor air pollution is one of the hu...</td>\n      <td>10.1016/j.envint.2018.09.043</td>\n      <td>Amoatey, Patrick; Omidvarborna, Hamid; Baawain...</td>\n      <td>Environment International</td>\n      <td>2018-12-31</td>\n      <td>256.198131</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 7 columns</p>\n</div>",
        "text/plain": "<__main__.SearchResults at 0x7ff6166ddac8>"
       }
      ]
     }
    },
    "7286b8badb294af9a397db67ecad89c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77a56e3eb5f045d393e7a468d717c994": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7be1d3d15f5b4e9d9ee2b4f9223da84f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15c23c2c03104af2bd42a5dfc02d8686",
       "IPY_MODEL_ca3c430cd1bc40019f3865dd45692bbe"
      ],
      "layout": "IPY_MODEL_cccc4bd597f34b049df91a08b9669379"
     }
    },
    "b4efed94a24a439a8694f3f0a488593e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8a3e8293e6f4320bba1daba3be7be3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1b50affced24423878211465d7a7a87",
       "IPY_MODEL_69f781068f1e4fcfb8cc5a71f8486e63"
      ],
      "layout": "IPY_MODEL_b4efed94a24a439a8694f3f0a488593e"
     }
    },
    "ca3c430cd1bc40019f3865dd45692bbe": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_6b65aa7979be4d45a129689a4ae65814",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "display_data",
        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>doi</th>\n      <th>authors</th>\n      <th>journal</th>\n      <th>publish_time</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36th International Symposium on Intensive Care...</td>\n      <td>P001 - Sepsis impairs the capillary response w...</td>\n      <td>10.1186/s13054-016-1208-6</td>\n      <td>Bateman, R. M.; Sharpe, M. D.; Jagger, J. E.; ...</td>\n      <td>Crit Care</td>\n      <td>2016 Apr 20</td>\n      <td>48.897161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XXIV World Allergy Congress 2015: Seoul, Korea...</td>\n      <td>A1 Pirfenidone inhibits TGF-b1-induced extrace...</td>\n      <td>10.1186/s40413-016-0096-1</td>\n      <td>Lee, Heung-Man; Park, Il-Ho; Shin, Jae-Min; Yo...</td>\n      <td>World Allergy Organ J</td>\n      <td>2016 Apr 19</td>\n      <td>48.850667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Both ERK1 and ERK2 Are Required for Enteroviru...</td>\n      <td>It has been demonstrated that MEK1, one of the...</td>\n      <td>10.3390/v7031344</td>\n      <td>Zhu, Meng; Duan, Hao; Gao, Meng; Zhang, Hao; P...</td>\n      <td>Viruses</td>\n      <td>2015 Mar 20</td>\n      <td>48.841823</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Activation of TORC1 Transcriptional Coactivato...</td>\n      <td>CREB is a prototypic bZIP transcription factor...</td>\n      <td>10.1091/mbc.E08-04-0369</td>\n      <td>Siu, Yeung-Tung; Ching, Yick-Pang; Jin, Dong-Yan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.837021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Decoying the cap- mRNA degradation system by a...</td>\n      <td>The major coat protein of the L-A double-stran...</td>\n      <td>NaN</td>\n      <td>Masison, D C; Blanc, A; Ribas, J C; Carroll, K...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.809539</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Phosphatidylinositol 4-Kinase IIIβ Is Required...</td>\n      <td>Phosphatidylinositol kinases (PI kinases) play...</td>\n      <td>10.1074/jbc.M111.312561</td>\n      <td>Yang, Ning; Ma, Ping; Lang, Jianshe; Zhang, Ya...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.482152</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Novel genotype of infectious bronchitis virus ...</td>\n      <td>Abstract Recombination events are known to con...</td>\n      <td>10.1016/j.vetmic.2019.01.020</td>\n      <td>Ma, Tianxin; Xu, Liwen; Ren, Mengting; Shen, J...</td>\n      <td>Veterinary Microbiology</td>\n      <td>2019-03-31</td>\n      <td>48.482058</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>IκB kinase ɛ (IKKɛ): A therapeutic target in i...</td>\n      <td>Abstract The innate immune system forms our fi...</td>\n      <td>10.1016/j.bcp.2013.01.007</td>\n      <td>Verhelst, Kelly; Verstrepen, Lynn; Carpentier,...</td>\n      <td>Biochemical Pharmacology</td>\n      <td>2013-04-01</td>\n      <td>48.481654</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>An educational programme for nursing college s...</td>\n      <td>BACKGROUND: The Middle Eastern Respiratory Syn...</td>\n      <td>10.1186/s12912-015-0065-y</td>\n      <td>Stirling, Bridget V; Harmston, Jennie; Alsobay...</td>\n      <td>BMC Nurs</td>\n      <td>2015 Apr 16</td>\n      <td>48.481506</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Chapter 19 Species Inquirendae in the Carnivora</td>\n      <td>Abstract There are at least 483 reports of car...</td>\n      <td>10.1016/B978-0-12-811349-3.00019-0</td>\n      <td>Duszynski, Donald W.; Kvičerová, Jana; Seville...</td>\n      <td>The Biology and Identification of the Coccidia...</td>\n      <td>2018-12-31</td>\n      <td>48.481080</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 7 columns</p>\n</div>",
        "text/plain": "<__main__.SearchResults at 0x7ff614db45c0>"
       }
      ]
     }
    },
    "cccc4bd597f34b049df91a08b9669379": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b50affced24423878211465d7a7a87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "What is known about transmission, incubation, and environmental stability?",
       "What do we know about COVID-19 risk factors?",
       "What do we know about virus genetics, origin, and evolution?",
       "What has been published about ethical and social science considerations",
       "What do we know about diagnostics and surveillance?",
       "What has been published about medical care?",
       "What do we know about vaccines and therapeutics?"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Task",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_f812bb34bc50426e9e116705969fde6f",
      "style": "IPY_MODEL_5a4ffac021a54cbd9ed5928d417a86ca"
     }
    },
    "f812bb34bc50426e9e116705969fde6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
